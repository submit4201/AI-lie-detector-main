annotated-types==0.7.0
anyio==4.9.0
certifi==2025.4.26
charset-normalizer==3.4.2
click==8.2.1
colorama==0.4.6
dnspython==2.7.0
dspy-ai
email_validator==2.2.0
fastapi==0.115.12
fastapi-cli==0.0.7
filelock==3.18.0
fsspec==2025.5.1
h11==0.16.0
httpcore==1.0.9
httptools==0.6.4
httpx==0.28.1
huggingface-hub==0.32.3
idna==3.10
itsdangerous==2.2.0
Jinja2==3.1.6
markdown-it-py==3.0.0
MarkupSafe==3.0.2
mdurl==0.1.2
mpmath==1.3.0
networkx==3.3
numpy==2.2.6
orjson==3.10.18
packaging==25.0
pillow==11.0.0
pydantic==2.11.5
pydantic-extra-types==2.10.5
pydantic-settings==2.9.1
pydantic_core==2.33.2
pydub==0.25.1
Pygments==2.19.1
python-dotenv==1.1.0
python-multipart==0.0.20
PyYAML==6.0.2
regex==2024.11.6
requests==2.32.4
rich==14.0.0
rich-toolkit==0.14.7
safetensors==0.5.3
setuptools==78.1.1
shellingham==1.5.4
sniffio==1.3.1
standard-aifc==3.13.0
standard-chunk==3.13.0
sympy==1.13.3
tokenizers==0.21.1
# Use a flexible torch spec so pip can pick the best available wheel for the platform
torch>=2.8.0,<3.0
# Compatible audio/vision packages; platform-specific wheels will be selected automatically when available
torchaudio>=2.7.0
torchvision>=0.22.0
# Intel / Intel Arc related optional packages (Windows):
# NOTE: `intel_extension_for_pytorch` (IPEX) is not always available on PyPI for all
# platforms and Python versions. Installing it via `pip install intel_extension_for_pytorch`
# may fail with "No matching distribution". Prefer installing IPEX manually following
# Intel's instructions or use conda channels where Intel provides prebuilt wheels.
# See: https://github.com/intel/intel-extension-for-pytorch
#
# If you want GPU acceleration on Windows with Intel Arc GPUs, alternatives include:
# - `torch-directml` (DirectML backend) which often provides easier GPU access on Windows.
#   Install with: `pip install torch-directml` (follow the project docs for compatibility).
# - Manually install IPEX following Intel docs or use Intel's provided wheels/conda channels.
#
# Commented out to avoid pip failing during a standard `pip install -r`.
#intel_extension_for_pytorch; platform_system == "Windows"
#intel-openmp; platform_system == "Windows"
tqdm==4.67.1
transformers==4.53.0
typer==0.16.0
typing-inspection==0.4.1
typing_extensions==4.14.0
ujson==5.10.0
urllib3==2.6.0
uvicorn==0.34.3
watchfiles==1.0.5
websockets==15.0.1
google-genai
python-dotenv
pytest==7.4.2
pytest-cov==4.1.0
onnxruntime-directml; platform_system == "Windows" and python_version < "3.11"
# OpenVINO and Optimum (commented out)
# The lines below are commented because `openvino-dev[onnx]` and `optimum[openvino]`
# can pull older, hard-to-build dependencies (e.g., old `scipy`/`numpy`) that cause
# long resolver/backtracking times or source builds on Windows. Install these only
# if you specifically need OpenVINO and are prepared to follow their platform
# instructions (or use conda channels / Intel-provided wheels).
# To install later (recommended):
#   pip install openvino-dev==2024.6.0  # or the OpenVINO version matching your platform
#   pip install optimum[openvino]
# Or use conda for a smoother install on Windows: https://docs.openvino.ai/
#openvino-dev[onnx]
#optimum[openvino]
pydub
pydantic